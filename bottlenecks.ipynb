{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We would like to design an experiment that can tell how time scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import learnHeat as lh\n",
    "import pygsp as pg\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.arange(4,101,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aner/Documents/Math/learning_graphs/learnHeat.py:159: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.maximum(np.array(taut)-gradient_z_to_tau(Ltp1, X, Htp1, taut)/et, 0)\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m X \u001b[39m=\u001b[39m lh\u001b[39m.\u001b[39mcreate_deltas(L,[\u001b[39m1\u001b[39m,\u001b[39m2.5\u001b[39m,\u001b[39m4\u001b[39m])\n\u001b[1;32m      7\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> 8\u001b[0m lh\u001b[39m.\u001b[39;49mlearn_heat(X,max_iter\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m      9\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     10\u001b[0m elapsed_time \u001b[39m=\u001b[39m end_time \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Documents/Math/learning_graphs/learnHeat.py:252\u001b[0m, in \u001b[0;36mlearn_heat\u001b[0;34m(X, L0, H0, tau0, alpha, beta, gamma1, gamma2, gamma3, max_iter, verbose)\u001b[0m\n\u001b[1;32m    249\u001b[0m cost_bar\u001b[39m.\u001b[39mset_description_str(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCOST: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m{:0.5f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(cal_cost(X,\u001b[39m \u001b[39mLt,\u001b[39m \u001b[39mHtp1,\u001b[39m \u001b[39mtaut,\u001b[39m \u001b[39malpha,\u001b[39m \u001b[39mbeta))\u001b[39m}\u001b[39;00m\u001b[39m (H updated)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    250\u001b[0m \u001b[39m# Step to update L and D\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[39m# Update L\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m Ltp1 \u001b[39m=\u001b[39m back_tracking(X, Lt, Htp1, taut, gamma2, alpha, beta, verbose)\n\u001b[1;32m    253\u001b[0m cost_bar\u001b[39m.\u001b[39mset_description_str(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCOST: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m{:0.5f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(cal_cost(X,\u001b[39m \u001b[39mLtp1,\u001b[39m \u001b[39mHtp1,\u001b[39m \u001b[39mtaut,\u001b[39m \u001b[39malpha,\u001b[39m \u001b[39mbeta))\u001b[39m}\u001b[39;00m\u001b[39m (L updated)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    255\u001b[0m \u001b[39m## Step to update tau and D\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Math/learning_graphs/learnHeat.py:49\u001b[0m, in \u001b[0;36mback_tracking\u001b[0;34m(X, Lt, Htp1, taut, gamma2, alpha, beta, verbose)\u001b[0m\n\u001b[1;32m     47\u001b[0m k \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     48\u001b[0m cond \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m gradient \u001b[39m=\u001b[39m gradient_z_to_L(Lt, X, Htp1, taut)\n\u001b[1;32m     50\u001b[0m \u001b[39mwhile\u001b[39;00m cond \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     c2 \u001b[39m=\u001b[39m (eta\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mk)\u001b[39m*\u001b[39mc2\n",
      "File \u001b[0;32m~/Documents/Math/learning_graphs/learnHeat.py:91\u001b[0m, in \u001b[0;36mgradient_z_to_L\u001b[0;34m(L, X, H, tau)\u001b[0m\n\u001b[1;32m     89\u001b[0m S \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(tau)\n\u001b[1;32m     90\u001b[0m H_list \u001b[39m=\u001b[39m H_matrix_to_list(H, N, S)\n\u001b[0;32m---> 91\u001b[0m on_signals \u001b[39m=\u001b[39m [(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m*\u001b[39mdtrAenLdL(L, A \u001b[39m=\u001b[39m Hs\u001b[39m@X\u001b[39m\u001b[39m.\u001b[39mT, nu \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mtau[s]) \u001b[39mfor\u001b[39;00m s, Hs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(H_list)]\n\u001b[1;32m     92\u001b[0m off_signal \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(L\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     93\u001b[0m \u001b[39mfor\u001b[39;00m s, Hs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(H_list):\n",
      "File \u001b[0;32m~/Documents/Math/learning_graphs/learnHeat.py:91\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     89\u001b[0m S \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(tau)\n\u001b[1;32m     90\u001b[0m H_list \u001b[39m=\u001b[39m H_matrix_to_list(H, N, S)\n\u001b[0;32m---> 91\u001b[0m on_signals \u001b[39m=\u001b[39m [(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m*\u001b[39mdtrAenLdL(L, A \u001b[39m=\u001b[39;49m Hs\u001b[39m@X\u001b[39;49m\u001b[39m.\u001b[39;49mT, nu \u001b[39m=\u001b[39;49m \u001b[39m-\u001b[39;49mtau[s]) \u001b[39mfor\u001b[39;00m s, Hs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(H_list)]\n\u001b[1;32m     92\u001b[0m off_signal \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(L\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     93\u001b[0m \u001b[39mfor\u001b[39;00m s, Hs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(H_list):\n",
      "File \u001b[0;32m~/Documents/Math/learning_graphs/learnHeat.py:117\u001b[0m, in \u001b[0;36mdtrAenLdL\u001b[0;34m(L, A, nu)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m nu \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    116\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mzeros(L\u001b[39m.\u001b[39mshape)\n\u001b[0;32m--> 117\u001b[0m \u001b[39mreturn\u001b[39;00m nu\u001b[39m*\u001b[39mdtrAeLdL(L \u001b[39m=\u001b[39;49m nu\u001b[39m*\u001b[39;49mL, A \u001b[39m=\u001b[39;49m A)\n",
      "File \u001b[0;32m~/Documents/Math/learning_graphs/learnHeat.py:121\u001b[0m, in \u001b[0;36mdtrAeLdL\u001b[0;34m(L, A)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdtrAeLdL\u001b[39m(L, A):\n\u001b[1;32m    120\u001b[0m     \u001b[39m# eigen decomposition\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     Eval, Evec \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49meig(L)\n\u001b[1;32m    122\u001b[0m     Eval \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreal(Eval)\n\u001b[1;32m    123\u001b[0m     Evec \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreal(Evec)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36meig\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py:1298\u001b[0m, in \u001b[0;36meig\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1296\u001b[0m _assert_stacked_2d(a)\n\u001b[1;32m   1297\u001b[0m _assert_stacked_square(a)\n\u001b[0;32m-> 1298\u001b[0m _assert_finite(a)\n\u001b[1;32m   1299\u001b[0m t, result_t \u001b[39m=\u001b[39m _commonType(a)\n\u001b[1;32m   1301\u001b[0m extobj \u001b[39m=\u001b[39m get_linalg_error_extobj(\n\u001b[1;32m   1302\u001b[0m     _raise_linalgerror_eigenvalues_nonconvergence)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py:195\u001b[0m, in \u001b[0;36m_assert_finite\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays:\n\u001b[1;32m    194\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m isfinite(a)\u001b[39m.\u001b[39mall():\n\u001b[0;32m--> 195\u001b[0m         \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mArray must not contain infs or NaNs\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "for n in N:\n",
    "    # measure time taken\n",
    "    G = pg.graphs.ErdosRenyi(n,p=0.4)\n",
    "    L = G.L.todense()\n",
    "    X = lh.create_deltas(L,[1,2.5,4])\n",
    "    start_time = time.time()\n",
    "    lh.learn_heat(X,max_iter=100)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    times.append(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.4513113498687744, 6.505238771438599, 6.8643903732299805]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data frames/list_of_times.pkl','wb') as f:\n",
    "    pickle.dump(times, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
